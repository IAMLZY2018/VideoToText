import sys
import os
import time
import subprocess
from pathlib import Path
from PyQt5.QtWidgets import (QApplication, QMainWindow, QVBoxLayout, QHBoxLayout,
                             QWidget, QPushButton, QLabel, QTextEdit, QFileDialog,
                             QProgressBar, QMessageBox, QComboBox, QCheckBox, QToolTip,
                             QTreeView, QListView, QAbstractItemView, QDialog, QScrollArea,
                             QGroupBox, QLineEdit)
from PyQt5.QtCore import QThread, pyqtSignal, Qt, QPoint
from PyQt5.QtGui import QFont, QCursor, QIntValidator
import whisper
import torch
from importlib.metadata import version, PackageNotFoundError
import requests
import zipfile
import argparse
from api_service import start_api_server
import shutil
# è¿™é‡Œæ˜¯æ ¸å¿ƒä»£ç 
class DependencyDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("ä¾èµ–æ£€æŸ¥")
        self.setFixedSize(400, 300)
        
        layout = QVBoxLayout()
        
        # çŠ¶æ€æ ‡ç­¾
        self.status_label = QLabel("æ­£åœ¨æ£€æŸ¥ä¾èµ–...")
        layout.addWidget(self.status_label)
        
        # è¿›åº¦æ¡
        self.progress = QProgressBar()
        layout.addWidget(self.progress)
        
        # æ—¥å¿—åŒºåŸŸ
        self.log = QTextEdit()
        self.log.setReadOnly(True)
        layout.addWidget(self.log)
        
        self.setLayout(layout)
        
    def log_message(self, message, replace_last=False):
        if replace_last:
            # åˆ é™¤æœ€åä¸€è¡Œ
            cursor = self.log.textCursor()
            cursor.movePosition(cursor.End)
            cursor.movePosition(cursor.StartOfLine, cursor.KeepAnchor)
            cursor.removeSelectedText()
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€è¡Œï¼Œåˆ é™¤æ¢è¡Œç¬¦
            if not self.log.toPlainText().endswith('\n') and self.log.toPlainText() != '':
                cursor.deletePreviousChar()
        
        self.log.append(message)
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.log.textCursor()
        cursor.movePosition(cursor.End)
        self.log.setTextCursor(cursor)
        QApplication.processEvents()
        
    def set_status(self, status):
        self.status_label.setText(status)
        QApplication.processEvents()
        
    def set_progress(self, value):
        self.progress.setValue(value)
        QApplication.processEvents()

def check_package_version(package_name, min_version):
    """æ£€æŸ¥åŒ…ç‰ˆæœ¬æ˜¯å¦æ»¡è¶³æœ€å°è¦æ±‚"""
    try:
        current_version = version(package_name)
        # å°†ç‰ˆæœ¬å·è½¬æ¢ä¸ºå…ƒç»„è¿›è¡Œæ¯”è¾ƒ
        current = tuple(map(int, current_version.split('.')))
        required = tuple(map(int, min_version.strip('>=').split('.')))
        return current >= required
    except PackageNotFoundError:
        return False
    except Exception:
        return False  # å¦‚æœç‰ˆæœ¬æ¯”è¾ƒå¤±è´¥ï¼Œè¿”å›False

def check_and_install_dependencies():
    try:
        # ç¡®ä¿æœ‰ä¸€ä¸ªQApplicationå®ä¾‹
        app = QApplication.instance()
        if app is None:
            app = QApplication(sys.argv)
        
        dialog = DependencyDialog()
        dialog.show()
        QApplication.processEvents()
        
        # å¿«é€Ÿæ£€æŸ¥åŸºæœ¬ä¾èµ–
        dialog.set_status("æ­£åœ¨å¿«é€Ÿæ£€æŸ¥åŸºæœ¬ä¾èµ–...")
        dialog.set_progress(10)
        
        # æ£€æŸ¥CUDAå¯ç”¨æ€§ï¼ˆä¸æ£€æŸ¥è¯¦ç»†ä¿¡æ¯ï¼‰
        cuda_available = torch.cuda.is_available()
        if cuda_available:
            dialog.log_message("âœ“ CUDA å¯ç”¨")
        else:
            dialog.log_message("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        
        # å¿«é€Ÿæ£€æŸ¥ffmpeg
        dialog.set_status("æ­£åœ¨æ£€æŸ¥ffmpeg...")
        dialog.set_progress(30)
        ffmpeg_found = False
        try:
            result = subprocess.run(['ffmpeg', '-version'], 
                                 capture_output=True, 
                                 text=True, 
                                 encoding='utf-8',
                                 errors='ignore')
            if result.returncode == 0:
                dialog.log_message("âœ“ ç³»ç»Ÿå·²å®‰è£…ffmpeg")
                ffmpeg_found = True
        except:
            pass
        
        if not ffmpeg_found and os.path.exists("ffmpeg.exe"):
            dialog.log_message("âœ“ æœ¬åœ°å·²æœ‰ffmpeg.exe")
            ffmpeg_found = True
        
        if not ffmpeg_found:
            dialog.log_message("âš ï¸ æœªæ‰¾åˆ°ffmpegï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶ä¸‹è½½")
        
        # å¿«é€Ÿæ£€æŸ¥Whisperæ¨¡å‹
        dialog.set_status("æ­£åœ¨æ£€æŸ¥Whisper...")
        dialog.set_progress(60)
        try:
            import whisper
            dialog.log_message("âœ“ Whisper å·²å®‰è£…")
        except ImportError:
            dialog.log_message("âš ï¸ Whisper æœªå®‰è£…ï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶å®‰è£…")
        
        # å®ŒæˆåŸºæœ¬æ£€æŸ¥
        dialog.set_status("åŸºæœ¬æ£€æŸ¥å®Œæˆ")
        dialog.set_progress(100)
        dialog.log_message("\nâœ“ åŸºæœ¬æ£€æŸ¥å®Œæˆï¼")
        QApplication.processEvents()
        time.sleep(0.5)  # å‡å°‘ç­‰å¾…æ—¶é—´
        dialog.accept()
        return True
        
    except Exception as e:
        if 'dialog' in locals():
            dialog.log_message(f"\né”™è¯¯: {str(e)}")
            dialog.set_status("æ£€æŸ¥å¤±è´¥")
            dialog.exec_()
        return False

class VideoProcessor(QThread):
    # ä¿¡å·å®šä¹‰
    log_signal = pyqtSignal(str)
    progress_signal = pyqtSignal(int)
    finished_signal = pyqtSignal()

    def __init__(self, video_files, output_folder, model_size="base", use_gpu=True, ffmpeg_path=""):
        super().__init__()
        self.video_files = video_files
        self.output_folder = output_folder
        self.model_size = model_size
        self.use_gpu = use_gpu and torch.cuda.is_available()
        self.is_running = True
        self.ffmpeg_path = ffmpeg_path
        self.whisper_model = None

    def run(self):
        try:
            # æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–
            if not self.check_and_install_dependencies():
                return

            # åˆå§‹åŒ–Whisperæ¨¡å‹
            self.log_signal.emit("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
            device = "cuda" if self.use_gpu else "cpu"
            self.log_signal.emit(f"ä½¿ç”¨è®¾å¤‡: {device}")

            # ç¦ç”¨ä¸å¿…è¦çš„è­¦å‘Š
            import warnings
            warnings.filterwarnings("ignore", message="Failed to launch Triton kernels")

            try:
                self.whisper_model = whisper.load_model(self.model_size, device=device)
                self.log_signal.emit(f"Whisper {self.model_size} æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                self.log_signal.emit(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                return

            total_files = len(self.video_files)
            self.log_signal.emit(f"å¼€å§‹å¤„ç†ï¼Œå…±å‘ç° {total_files} ä¸ªè§†é¢‘æ–‡ä»¶")

            for i, video_path in enumerate(self.video_files):
                if not self.is_running:
                    break

                start_time = time.time()
                video_name = Path(video_path).stem
                current_time = time.strftime("%H%M%S")  # è·å–å½“å‰æ—¶é—´ï¼ˆæ—¶åˆ†ç§’ï¼‰

                self.log_signal.emit(f"æ­£åœ¨å¤„ç†: {video_name}")

                try:
                    # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
                    audio_path = self.extract_audio_with_ffmpeg(video_path, video_name)

                    # ä½¿ç”¨Whisperè½¬æ¢ä¸ºæ–‡å­—
                    text_content = self.audio_to_text_with_whisper(audio_path)

                    # ä¿å­˜æ–‡æœ¬æ–‡ä»¶ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
                    txt_filename = f"{video_name}_{current_time}.txt"
                    txt_path = os.path.join(self.output_folder, txt_filename)
                    with open(txt_path, 'w', encoding='utf-8') as f:
                        f.write(text_content)

                    # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    if os.path.exists(audio_path):
                        os.remove(audio_path)

                    # è®¡ç®—å¤„ç†æ—¶é—´å’Œæ–‡å­—æ•°é‡
                    end_time = time.time()
                    duration = end_time - start_time
                    word_count = len(text_content)
                    remaining = total_files - i - 1

                    self.log_signal.emit(f"å®Œæˆ: {video_name}")
                    self.log_signal.emit(f"è€—æ—¶: {duration:.2f}ç§’, æ–‡å­—æ•°é‡: {word_count}, å‰©ä½™: {remaining}ä¸ªæ–‡ä»¶")
                    self.log_signal.emit(f"è¾“å‡ºæ–‡ä»¶: {txt_filename}")
                    self.log_signal.emit(f"è¾“å‡ºè·¯å¾„: {txt_path}")
                    self.log_signal.emit("-" * 50)

                except Exception as e:
                    self.log_signal.emit(f"å¤„ç†å¤±è´¥ {video_name}: {str(e)}")

                # æ›´æ–°è¿›åº¦
                progress = int((i + 1) / total_files * 100)
                self.progress_signal.emit(progress)

            self.log_signal.emit("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")

        except Exception as e:
            self.log_signal.emit(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

        finally:
            self.finished_signal.emit()

    def extract_audio_with_ffmpeg(self, video_path, video_name):
        """ä½¿ç”¨ffmpegä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
        try:
            # ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            temp_audio_path = os.path.join(self.output_folder, f"temp_audio_{video_name}.wav")

            # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ffmpegè·¯å¾„
            if self.ffmpeg_path:
                ffmpeg_cmd = self.ffmpeg_path
            else:
                # å°è¯•å¤šç§ffmpegè°ƒç”¨æ–¹å¼ä½œä¸ºå¤‡é€‰
                ffmpeg_commands = [
                    'ffmpeg',
                    'ffmpeg.exe',
                    r'C:\ffmpeg\bin\ffmpeg.exe',
                    r'C:\Program Files\ffmpeg\bin\ffmpeg.exe'
                ]

                ffmpeg_cmd = None
                for cmd in ffmpeg_commands:
                    try:
                        result = subprocess.run([cmd, '-version'], 
                                             capture_output=True, 
                                             text=True, 
                                             encoding='utf-8',  # æŒ‡å®šç¼–ç 
                                             errors='ignore',   # å¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦
                                             timeout=5)
                        if result.returncode == 0:
                            ffmpeg_cmd = cmd
                            break
                    except:
                        continue

                if not ffmpeg_cmd:
                    raise Exception("æ‰¾ä¸åˆ°å¯ç”¨çš„ffmpegï¼Œè¯·æ‰‹åŠ¨é€‰æ‹©ffmpegè·¯å¾„")

            # æ„å»ºffmpegå‘½ä»¤
            cmd = [
                ffmpeg_cmd,
                '-i', video_path,
                '-vn',  # ä¸è¦è§†é¢‘
                '-acodec', 'pcm_s16le',
                '-ar', '16000',  # 16kHzé‡‡æ ·ç‡
                '-ac', '1',  # å•å£°é“
                '-y',  # è¦†ç›–ç°æœ‰æ–‡ä»¶
                temp_audio_path
            ]

            self.log_signal.emit(f"æå–éŸ³é¢‘: {video_name}")
            self.log_signal.emit(f"ä½¿ç”¨ffmpeg: {ffmpeg_cmd}")

            # æ‰§è¡Œffmpegå‘½ä»¤
            try:
                result = subprocess.run(cmd, 
                                     capture_output=True, 
                                     text=True, 
                                     encoding='utf-8',  # æŒ‡å®šç¼–ç 
                                     errors='ignore',   # å¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦
                                     timeout=300)
            except:
                # å¦‚æœç›´æ¥è°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨shell=True
                cmd_str = ' '.join([f'"{arg}"' if ' ' in arg else arg for arg in cmd])
                result = subprocess.run(cmd_str, 
                                     capture_output=True, 
                                     text=True, 
                                     encoding='utf-8',  # æŒ‡å®šç¼–ç 
                                     errors='ignore',   # å¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦
                                     shell=True, 
                                     timeout=300)

            if result.returncode != 0:
                raise Exception(f"ffmpegé”™è¯¯: {result.stderr}")

            if not os.path.exists(temp_audio_path):
                raise Exception("éŸ³é¢‘æ–‡ä»¶æå–å¤±è´¥")

            return temp_audio_path

        except Exception as e:
            raise Exception(f"éŸ³é¢‘æå–å¤±è´¥: {str(e)}")

    def audio_to_text_with_whisper(self, audio_path):
        """ä½¿ç”¨Whisperå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—"""
        try:
            self.log_signal.emit("æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
            self.log_signal.emit(f"ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶: {audio_path}")

            # ä½¿ç”¨Whisperè¿›è¡Œè½¬å½•
            result = self.whisper_model.transcribe(
                audio_path,
                language='zh',           # æŒ‡å®šä¸­æ–‡
                task='transcribe',       # è½¬å½•ä»»åŠ¡
                fp16=torch.cuda.is_available(),  # å¦‚æœæœ‰GPUåˆ™ä½¿ç”¨fp16åŠ é€Ÿ
                initial_prompt="ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„è½¬å½•æ–‡æœ¬ï¼ŒåŒ…å«æ ‡ç‚¹ç¬¦å·ï¼š",  # æç¤ºè¯ä»¥å¼•å¯¼è¾“å‡ºå¸¦æ ‡ç‚¹çš„æ–‡æœ¬
                word_timestamps=True,    # å¯ç”¨è¯çº§æ—¶é—´æˆ³ï¼Œæœ‰åŠ©äºæ›´å¥½çš„åˆ†æ®µ
                condition_on_previous_text=True,  # è€ƒè™‘ä¸Šä¸‹æ–‡
                temperature=0.0,         # é™ä½éšæœºæ€§ï¼Œä½¿è¾“å‡ºæ›´ç¨³å®š
                best_of=1,              # åªç”Ÿæˆä¸€ä¸ªç»“æœ
                no_speech_threshold=0.6  # è°ƒæ•´æ— è¯­éŸ³æ£€æµ‹é˜ˆå€¼
            )

            # è·å–è½¬å½•æ–‡æœ¬
            text = result["text"].strip()
            self.log_signal.emit(f"è¯†åˆ«å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")

            if not text:
                self.log_signal.emit("è­¦å‘Š: æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
                return "æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹"

            # å¦‚æœæ–‡æœ¬ä¸­ç¼ºå°‘æ ‡ç‚¹ï¼Œå°è¯•è¿›è¡Œç®€å•çš„åˆ†æ®µå¤„ç†
            if len(text) > 0 and not any(p in text for p in 'ï¼Œã€‚ï¼ï¼Ÿã€'):
                self.log_signal.emit("æ­£åœ¨ä¼˜åŒ–æ–‡æœ¬æ ¼å¼...")
                # ä½¿ç”¨æ—¶é—´æˆ³ä¿¡æ¯è¿›è¡Œåˆ†æ®µ
                segments = result.get("segments", [])
                formatted_text = ""
                for segment in segments:
                    segment_text = segment.get("text", "").strip()
                    if segment_text:
                        # å¦‚æœåˆ†æ®µæ–‡æœ¬æœ«å°¾æ²¡æœ‰æ ‡ç‚¹ï¼Œæ·»åŠ å¥å·
                        if not segment_text[-1] in 'ï¼Œã€‚ï¼ï¼Ÿã€':
                            segment_text += 'ã€‚'
                        formatted_text += segment_text + '\n'
                text = formatted_text.strip()

            return text

        except Exception as e:
            self.log_signal.emit(f"è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}")
            raise Exception(f"è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}")

    def stop(self):
        self.is_running = False

    def check_and_install_dependencies(self):
        """æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–"""
        try:
            # æ£€æŸ¥CUDAå·¥å…·åŒ…ï¼ˆå¦‚æœä½¿ç”¨GPUï¼‰
            if self.use_gpu:
                try:
                    import triton
                    self.log_signal.emit("âœ“ Triton CUDA å·¥å…·åŒ…å·²å®‰è£…")
                except ImportError:
                    self.log_signal.emit("âš ï¸ Triton CUDA å·¥å…·åŒ…æœªå®‰è£…ï¼ŒæŸäº›GPUåŠ é€ŸåŠŸèƒ½å°†ä¸å¯ç”¨")

            # æ£€æŸ¥ffmpeg
            if not self.ffmpeg_path:
                try:
                    result = subprocess.run(['ffmpeg', '-version'], 
                                         capture_output=True, 
                                         text=True, 
                                         encoding='utf-8',
                                         errors='ignore')
                    if result.returncode == 0:
                        self.log_signal.emit("âœ“ ç³»ç»Ÿå·²å®‰è£…ffmpeg")
                        self.ffmpeg_path = 'ffmpeg'
                    else:
                        raise Exception("ffmpegæ‰§è¡Œå¤±è´¥")
                except:
                    # å°è¯•ä¸‹è½½ffmpeg
                    self.log_signal.emit("æ­£åœ¨ä¸‹è½½ffmpeg...")
                    if not self.download_ffmpeg():
                        self.log_signal.emit("âŒ ffmpegä¸‹è½½å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ä¸‹è½½å¹¶æ”¾ç½®åœ¨ç¨‹åºç›®å½•")
                        return False

            # æ£€æŸ¥whisper
            try:
                import whisper
            except ImportError:
                self.log_signal.emit("æ­£åœ¨å®‰è£…whisper...")
                try:
                    subprocess.check_call([
                        sys.executable, "-m", "pip", "install",
                        "-i", "https://pypi.tuna.tsinghua.edu.cn/simple",
                        "openai-whisper"
                    ])
                except Exception as e:
                    self.log_signal.emit(f"âŒ whisperå®‰è£…å¤±è´¥: {str(e)}")
                    return False

            return True

        except Exception as e:
            self.log_signal.emit(f"ä¾èµ–æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False

    def download_ffmpeg(self):
        """ä¸‹è½½ffmpeg"""
        try:
            url = "https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-win64-gpl.zip"
            
            # ä½¿ç”¨requestsä¸‹è½½
            response = requests.get(url, stream=True)
            total_size = int(response.headers.get('content-length', 0))
            block_size = 1024  # 1KB
            
            with open("ffmpeg.zip", "wb") as f:
                downloaded = 0
                for data in response.iter_content(block_size):
                    downloaded += len(data)
                    f.write(data)
                    progress = (downloaded / total_size) * 100
                    self.log_signal.emit(f"ä¸‹è½½è¿›åº¦: {progress:.1f}%")
            
            self.log_signal.emit("æ­£åœ¨è§£å‹ffmpeg...")
            with zipfile.ZipFile("ffmpeg.zip", "r") as zip_ref:
                zip_ref.extractall("ffmpeg_temp")
            
            # ç§»åŠ¨ffmpeg.exe
            ffmpeg_exe = next(Path("ffmpeg_temp").rglob("ffmpeg.exe"))
            if os.path.exists("ffmpeg.exe"):
                os.remove("ffmpeg.exe")
            os.rename(ffmpeg_exe, "ffmpeg.exe")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            shutil.rmtree("ffmpeg_temp")
            os.remove("ffmpeg.zip")
            
            self.ffmpeg_path = "ffmpeg.exe"
            self.log_signal.emit("âœ“ ffmpeg å®‰è£…å®Œæˆ")
            return True
            
        except Exception as e:
            self.log_signal.emit(f"âŒ ffmpeg ä¸‹è½½å¤±è´¥: {str(e)}")
            return False

class HelpButton(QPushButton):
    def __init__(self, parent=None):
        super().__init__("?", parent)
        self.setFixedSize(20, 20)
        self.setStyleSheet("""
            QPushButton {
                border: 1px solid #999;
                border-radius: 10px;
                background-color: #f0f0f0;
                color: #666;
                font-size: 12px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #e0e0e0;
            }
        """)
        self.help_text = ("æ¨¡å‹é€‰æ‹©æŒ‡å—ï¼š\n"
                         "â€¢ â‰¥10GB æ˜¾å­˜ï¼šlargeï¼ˆé€‚åˆæœ€ä½³è´¨é‡ï¼‰\n"
                         "â€¢ â‰¥8GB æ˜¾å­˜ï¼šmediumï¼ˆå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡ï¼‰\n"
                         "â€¢ â‰¥5GB æ˜¾å­˜ï¼šsmallï¼ˆå¹³è¡¡å†…å­˜å’Œè´¨é‡ï¼‰\n"
                         "â€¢ <5GB æ˜¾å­˜ï¼šbaseï¼ˆé€‚åˆåŸºæœ¬ä½¿ç”¨ï¼‰\n"
                         "â€¢ CPU æ¨¡å¼ï¼šbaseï¼ˆé€‚åˆCPUæ¨¡å¼ï¼‰")
        
        # è®¾ç½®å·¥å…·æç¤ºæ ·å¼
        QToolTip.setFont(QFont('Microsoft YaHei', 9))
        
        # è¿æ¥ç‚¹å‡»äº‹ä»¶
        self.clicked.connect(self.show_tooltip)
        
        # è®¾ç½®é¼ æ ‡è¿½è¸ª
        self.setMouseTracking(True)
        
    def enterEvent(self, event):
        # é¼ æ ‡è¿›å…¥æ—¶æ˜¾ç¤ºæç¤º
        QToolTip.showText(QCursor.pos(), self.help_text, self)
        
    def leaveEvent(self, event):
        # é¼ æ ‡ç¦»å¼€æ—¶éšè—æç¤º
        QToolTip.hideText()
        
    def show_tooltip(self):
        # ç‚¹å‡»æ—¶æ˜¾ç¤ºæç¤º
        pos = self.mapToGlobal(QPoint(self.width(), 0))
        QToolTip.showText(pos, self.help_text, self)


class ConfirmDialog(QDialog):
    def __init__(self, files, parent=None):
        super().__init__(parent)
        self.files = files
        self.init_ui()

    def init_ui(self):
        self.setWindowTitle("è½¬æ¢ç¡®è®¤")
        self.setMinimumWidth(500)
        layout = QVBoxLayout()

        # æ·»åŠ æ–‡ä»¶æ•°é‡ä¿¡æ¯
        info_layout = QHBoxLayout()
        info_layout.addWidget(QLabel(f"å¾…è½¬æ¢æ–‡ä»¶æ•°é‡: {len(self.files)}"))
        
        # ä¼°ç®—æ€»æ—¶é—´ï¼ˆå‡è®¾æ¯åˆ†é’Ÿè§†é¢‘éœ€è¦20ç§’å¤„ç†ï¼‰
        total_duration = 0
        for file in self.files:
            try:
                # ä½¿ç”¨ffprobeè·å–è§†é¢‘æ—¶é•¿
                cmd = ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', 
                      '-of', 'default=noprint_wrappers=1:nokey=1', file]
                result = subprocess.run(cmd, capture_output=True, text=True)
                duration = float(result.stdout.strip())
                total_duration += duration
            except:
                # å¦‚æœæ— æ³•è·å–æ—¶é•¿ï¼Œå‡è®¾æ˜¯5åˆ†é’Ÿ
                total_duration += 300

        # ä¼°ç®—å¤„ç†æ—¶é—´ï¼ˆå‡è®¾å¤„ç†é€Ÿåº¦æ˜¯å®é™…æ—¶é—´çš„1/3ï¼‰
        estimated_time = total_duration / 3
        hours = int(estimated_time // 3600)
        minutes = int((estimated_time % 3600) // 60)
        seconds = int(estimated_time % 60)
        
        time_label = QLabel(f"é¢„è®¡å¤„ç†æ—¶é—´: {hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds}ç§’")
        info_layout.addWidget(time_label)
        layout.addLayout(info_layout)

        # æ·»åŠ æ–‡ä»¶åˆ—è¡¨
        list_label = QLabel("æ–‡ä»¶åˆ—è¡¨:")
        layout.addWidget(list_label)

        # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨æ˜¾ç¤ºåŒºåŸŸï¼ˆå¸¦æ»šåŠ¨æ¡ï¼‰
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setMinimumHeight(300)
        
        content_widget = QWidget()
        content_layout = QVBoxLayout(content_widget)

        # æ·»åŠ æ¯ä¸ªæ–‡ä»¶çš„ä¿¡æ¯
        for i, file in enumerate(self.files, 1):
            file_name = Path(file).name
            file_size = os.path.getsize(file) / (1024 * 1024)  # è½¬æ¢ä¸ºMB
            file_label = QLabel(f"{i}. {file_name} ({file_size:.1f}MB)")
            file_label.setToolTip(file)  # é¼ æ ‡æ‚¬åœæ˜¾ç¤ºå®Œæ•´è·¯å¾„
            content_layout.addWidget(file_label)

        content_layout.addStretch()
        scroll.setWidget(content_widget)
        layout.addWidget(scroll)

        # æ·»åŠ æŒ‰é’®
        btn_layout = QHBoxLayout()
        ok_btn = QPushButton("å¼€å§‹è½¬æ¢")
        cancel_btn = QPushButton("å–æ¶ˆ")
        ok_btn.clicked.connect(self.accept)
        cancel_btn.clicked.connect(self.reject)
        btn_layout.addWidget(ok_btn)
        btn_layout.addWidget(cancel_btn)
        layout.addLayout(btn_layout)

        self.setLayout(layout)


class VideoAudioExtractorApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.video_files = []
        self.output_folder = ""
        self.processor_thread = None
        self.ffmpeg_path = ""
        self.api_server = None
        self.init_ui()
        self.check_dependencies()

    def get_recommended_model(self):
        """è·å–æ¨èçš„æ¨¡å‹å¤§å°"""
        if torch.cuda.is_available():
            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
            if gpu_memory_gb >= 10:
                return "large", "é€‚åˆæœ€ä½³è´¨é‡"
            elif gpu_memory_gb >= 8:
                return "medium", "å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡"
            elif gpu_memory_gb >= 5:
                return "small", "å¹³è¡¡å†…å­˜å’Œè´¨é‡"
            else:
                return "base", "é€‚åˆåŸºæœ¬ä½¿ç”¨"
        else:
            # CPUæ¨¡å¼ä¸‹æ¨èä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
            return "base", "é€‚åˆCPUæ¨¡å¼"

    def init_ui(self):
        self.setWindowTitle("è§†é¢‘éŸ³é¢‘è½¬æ–‡å­—å·¥å…· (GPUåŠ é€Ÿç‰ˆ)")
        self.setGeometry(100, 100, 900, 700)

        # åˆ›å»ºä¸­å¤®çª—å£éƒ¨ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)

        # åˆ›å»ºä¸»å¸ƒå±€
        main_layout = QVBoxLayout()
        central_widget.setLayout(main_layout)

        # è®¾ç½®å­—ä½“
        font = QFont("Microsoft YaHei", 10)
        self.setFont(font)

        # æ ‡é¢˜
        title_label = QLabel("è§†é¢‘éŸ³é¢‘è½¬æ–‡å­—æå–å·¥å…· (GPUåŠ é€Ÿç‰ˆ)")
        title_label.setAlignment(Qt.AlignCenter)
        title_label.setFont(QFont("Microsoft YaHei", 16, QFont.Bold))
        main_layout.addWidget(title_label)

        # æ·»åŠ ffmpegè·¯å¾„é€‰æ‹©
        ffmpeg_layout = QHBoxLayout()
        self.ffmpeg_label = QLabel("æœªé€‰æ‹©ffmpegè·¯å¾„")
        self.ffmpeg_btn = QPushButton("é€‰æ‹©ffmpeg")
        self.ffmpeg_btn.clicked.connect(self.select_ffmpeg_path)
        ffmpeg_layout.addWidget(QLabel("ffmpegè·¯å¾„:"))
        ffmpeg_layout.addWidget(self.ffmpeg_label, 1)
        ffmpeg_layout.addWidget(self.ffmpeg_btn)
        main_layout.addLayout(ffmpeg_layout)

        # æ¨¡å‹è®¾ç½®éƒ¨åˆ†
        model_layout = QHBoxLayout()
        model_layout.addWidget(QLabel("Whisperæ¨¡å‹:"))

        self.model_combo = QComboBox()
        self.model_combo.addItems(["tiny", "base", "small", "medium", "large"])
        # è®¾ç½®æ¨èçš„æ¨¡å‹å¤§å°
        recommended_model, reason = self.get_recommended_model()
        self.model_combo.setCurrentText(recommended_model)
        model_layout.addWidget(self.model_combo)

        # æ·»åŠ å¸®åŠ©æŒ‰é’®
        help_btn = HelpButton(self)
        model_layout.addWidget(help_btn)

        # æ·»åŠ æ¨èæ ‡è®°
        self.model_recommended_label = QLabel(f"ï¼ˆæ¨èï¼š{reason}ï¼‰")
        self.model_recommended_label.setStyleSheet("color: green;")
        model_layout.addWidget(self.model_recommended_label)

        self.gpu_checkbox = QCheckBox("ä½¿ç”¨GPUåŠ é€Ÿ")
        self.gpu_checkbox.setChecked(torch.cuda.is_available())
        self.gpu_checkbox.setEnabled(torch.cuda.is_available())
        model_layout.addWidget(self.gpu_checkbox)

        model_layout.addStretch()
        main_layout.addLayout(model_layout)

        # å½“æ¨¡å‹é€‰æ‹©æ”¹å˜æ—¶æ›´æ–°æ¨èæ ‡è®°
        self.model_combo.currentTextChanged.connect(self.update_model_recommendation)

        # é€‰æ‹©è§†é¢‘æ–‡ä»¶/æ–‡ä»¶å¤¹éƒ¨åˆ†
        video_layout = QHBoxLayout()
        self.video_label = QLabel("æœªé€‰æ‹©è§†é¢‘æ–‡ä»¶")
        self.video_select_btn = QPushButton("é€‰æ‹©è§†é¢‘")
        self.video_select_btn.clicked.connect(self.select_videos)
        
        video_layout.addWidget(QLabel("è§†é¢‘é€‰æ‹©:"))
        video_layout.addWidget(self.video_label, 1)
        video_layout.addWidget(self.video_select_btn)
        main_layout.addLayout(video_layout)

        # é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹éƒ¨åˆ†
        output_layout = QHBoxLayout()
        self.output_label = QLabel("æœªé€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹")
        self.output_btn = QPushButton("é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹")
        self.output_btn.clicked.connect(self.select_output_folder)

        output_layout.addWidget(QLabel("è¾“å‡ºæ–‡ä»¶å¤¹:"))
        output_layout.addWidget(self.output_label, 1)
        output_layout.addWidget(self.output_btn)
        main_layout.addLayout(output_layout)

        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        main_layout.addWidget(self.progress_bar)

        # æ§åˆ¶æŒ‰é’®
        button_layout = QHBoxLayout()
        self.start_btn = QPushButton("å¼€å§‹è½¬æ¢")
        self.stop_btn = QPushButton("åœæ­¢è½¬æ¢")
        self.clear_log_btn = QPushButton("æ¸…ç©ºæ—¥å¿—")

        self.start_btn.clicked.connect(self.start_conversion)
        self.stop_btn.clicked.connect(self.stop_conversion)
        self.clear_log_btn.clicked.connect(self.clear_log)

        self.stop_btn.setEnabled(False)

        button_layout.addWidget(self.start_btn)
        button_layout.addWidget(self.stop_btn)
        button_layout.addWidget(self.clear_log_btn)
        button_layout.addStretch()
        main_layout.addLayout(button_layout)

        # æ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
        main_layout.addWidget(QLabel("å¤„ç†æ—¥å¿—:"))
        self.log_text = QTextEdit()
        self.log_text.setMaximumHeight(350)
        main_layout.addWidget(self.log_text)

        # çŠ¶æ€æç¤º
        gpu_status = "GPUå¯ç”¨" if torch.cuda.is_available() else "GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU"
        status_label = QLabel(f"çŠ¶æ€: {gpu_status} | ä¾èµ–: ffmpeg, openai-whisper, torch")
        status_label.setStyleSheet("color: #666; font-size: 9px;")
        main_layout.addWidget(status_label)

        # APIæœåŠ¡æ§åˆ¶éƒ¨åˆ†
        api_group = QGroupBox("APIæœåŠ¡æ§åˆ¶")
        api_layout = QVBoxLayout()

        # APIæœåŠ¡æ§åˆ¶æŒ‰é’®å’ŒçŠ¶æ€æ˜¾ç¤º
        api_controls = QHBoxLayout()
        self.api_start_btn = QPushButton("å¯åŠ¨APIæœåŠ¡")
        self.api_stop_btn = QPushButton("åœæ­¢APIæœåŠ¡")
        self.api_status_label = QLabel("æœåŠ¡çŠ¶æ€: æœªå¯åŠ¨")
        
        self.api_start_btn.clicked.connect(self.start_api_service)
        self.api_stop_btn.clicked.connect(self.stop_api_service)
        self.api_stop_btn.setEnabled(False)

        api_controls.addWidget(self.api_start_btn)
        api_controls.addWidget(self.api_stop_btn)
        api_controls.addWidget(self.api_status_label)
        api_controls.addStretch()

        # APIæœåŠ¡é…ç½®
        api_config = QHBoxLayout()
        self.api_host_input = QLineEdit("0.0.0.0")
        self.api_port_input = QLineEdit("8000")
        self.api_port_input.setValidator(QIntValidator(1, 65535))
        
        api_config.addWidget(QLabel("ä¸»æœº:"))
        api_config.addWidget(self.api_host_input)
        api_config.addWidget(QLabel("ç«¯å£:"))
        api_config.addWidget(self.api_port_input)
        api_config.addStretch()

        # APIæœåŠ¡ç»Ÿè®¡ä¿¡æ¯
        self.api_stats = QLabel("ä»»åŠ¡ç»Ÿè®¡: æ€»æ•° 0 | å·²å®Œæˆ 0")

        api_layout.addLayout(api_controls)
        api_layout.addLayout(api_config)
        api_layout.addWidget(self.api_stats)

        api_group.setLayout(api_layout)
        main_layout.addWidget(api_group)

        # GPUè¯Šæ–­æŒ‰é’®
        diag_layout = QHBoxLayout()
        self.gpu_diag_btn = QPushButton("GPUè¯Šæ–­")
        self.gpu_diag_btn.clicked.connect(self.show_gpu_diagnostic)
        diag_layout.addWidget(self.gpu_diag_btn)
        diag_layout.addStretch()
        main_layout.addLayout(diag_layout)

    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–é¡¹"""
        # æ£€æŸ¥ffmpeg
        ffmpeg_found = False
        try:
            # å°è¯•å¤šç§æ–¹å¼æŸ¥æ‰¾ffmpeg
            result = subprocess.run(['ffmpeg', '-version'], 
                                 capture_output=True, 
                                 text=True, 
                                 encoding='utf-8',
                                 errors='ignore',
                                 shell=True)
            if result.returncode == 0:
                # æå–ç‰ˆæœ¬ä¿¡æ¯
                version_line = result.stdout.split('\n')[0]
                self.log_message(f"âœ“ {version_line}")
                # è·å–ffmpegè·¯å¾„
                where_result = subprocess.run('where ffmpeg', 
                                           capture_output=True, 
                                           text=True, 
                                           encoding='utf-8',
                                           errors='ignore',
                                           shell=True)
                if where_result.returncode == 0:
                    ffmpeg_path = where_result.stdout.strip().split('\n')[0]
                    self.ffmpeg_path = ffmpeg_path
                    self.ffmpeg_label.setText(f"å·²è‡ªåŠ¨æ£€æµ‹: {ffmpeg_path}")
                    self.ffmpeg_btn.setEnabled(False)  # ç¦ç”¨é€‰æ‹©æŒ‰é’®
                    ffmpeg_found = True
                else:
                    self.ffmpeg_path = 'ffmpeg'  # ä½¿ç”¨å‘½ä»¤åä½œä¸ºé»˜è®¤å€¼
                    self.ffmpeg_label.setText("å·²åœ¨ç³»ç»ŸPATHä¸­æ‰¾åˆ°ffmpeg")
                    self.ffmpeg_btn.setEnabled(False)  # ç¦ç”¨é€‰æ‹©æŒ‰é’®
                    ffmpeg_found = True
            else:
                self.log_message("âœ— ffmpeg æ‰§è¡Œå¤±è´¥")
        except Exception as e:
            self.log_message(f"âœ— ffmpeg æ£€æµ‹å¼‚å¸¸: {str(e)}")

        # å¦‚æœç¬¬ä¸€æ¬¡æ£€æµ‹å¤±è´¥ï¼Œå°è¯•å…¶ä»–è·¯å¾„
        if not ffmpeg_found:
            common_paths = [
                'ffmpeg.exe',
                r'C:\ffmpeg\bin\ffmpeg.exe',
                r'C:\Program Files\ffmpeg\bin\ffmpeg.exe'
            ]

            for path in common_paths:
                try:
                    result = subprocess.run([path, '-version'], 
                                         capture_output=True, 
                                         text=True,
                                         encoding='utf-8',
                                         errors='ignore')
                    if result.returncode == 0:
                        self.log_message(f"âœ“ ffmpeg æ‰¾åˆ°: {path}")
                        self.ffmpeg_path = path
                        self.ffmpeg_label.setText(f"å·²è‡ªåŠ¨æ£€æµ‹: {path}")
                        self.ffmpeg_btn.setEnabled(False)  # ç¦ç”¨é€‰æ‹©æŒ‰é’®
                        ffmpeg_found = True
                        break
                except:
                    continue

            if not ffmpeg_found:
                self.log_message("âœ— ffmpeg æœªæ‰¾åˆ°")
                self.log_message("ğŸ’¡ è¯·æ£€æŸ¥:")
                self.log_message("   1. ffmpegæ˜¯å¦æ­£ç¡®å®‰è£…")
                self.log_message("   2. PATHç¯å¢ƒå˜é‡æ˜¯å¦åŒ…å«ffmpegè·¯å¾„")
                self.log_message("   3. é‡å¯ç¨‹åºæˆ–é‡å¯ç”µè„‘")
                self.log_message("   4. æˆ–è€…æ‰‹åŠ¨é€‰æ‹©ffmpeg.exe")
                self.ffmpeg_btn.setEnabled(True)  # å¯ç”¨é€‰æ‹©æŒ‰é’®

        # è¯¦ç»†æ£€æŸ¥GPUçŠ¶æ€
        self.log_message("=" * 40)
        self.log_message("GPU æ£€æµ‹æŠ¥å‘Š:")

        # æ£€æŸ¥PyTorch
        self.log_message(f"PyTorchç‰ˆæœ¬: {torch.__version__}")

        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            self.log_message("âœ“ CUDA å¯ç”¨")
            self.log_message(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            self.log_message(f"GPUæ•°é‡: {torch.cuda.device_count()}")

            # æ£€æŸ¥æ¯ä¸ªGPU
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_mem = torch.cuda.get_device_properties(i).total_memory / 1024 ** 3
                self.log_message(f"GPU {i}: {gpu_name} ({gpu_mem:.1f}GB)")

            # è·å–æ¨èæ¨¡å‹å’ŒåŸå› 
            recommended_model, reason = self.get_recommended_model()
            self.log_message(f"ğŸ’¡ æ¨èä½¿ç”¨ {recommended_model} æ¨¡å‹ï¼ˆ{reason}ï¼‰")

            # æ£€æŸ¥CUDAå·¥å…·åŒ…
            try:
                import triton
                self.log_message("âœ“ Triton CUDA å·¥å…·åŒ…å·²å®‰è£…")
            except ImportError:
                self.log_message("âš ï¸ Triton CUDA å·¥å…·åŒ…æœªå®‰è£…")
                self.log_message("ğŸ’¡ å»ºè®®è¿è¡Œ: pip install triton")
                self.log_message("  è¿™å°†å¯ç”¨é¢å¤–çš„GPUåŠ é€ŸåŠŸèƒ½")

        else:
            self.log_message("âœ— CUDA ä¸å¯ç”¨")
            self.log_message("å¯èƒ½åŸå› :")
            self.log_message("  1. æ²¡æœ‰NVIDIA GPU")
            self.log_message("  2. æ˜¾å¡é©±åŠ¨æœªå®‰è£…")
            self.log_message("  3. PyTorchç‰ˆæœ¬ä¸æ”¯æŒCUDA")
            self.log_message("  4. CUDAå·¥å…·åŒ…æœªå®‰è£…")

            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–GPU
            try:
                import platform
                if platform.system() == "Darwin":  # macOS
                    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                        self.log_message("âœ“ æ£€æµ‹åˆ° Apple Silicon GPU (MPS)")
                        self.log_message("æ³¨æ„: Whisperæš‚ä¸æ”¯æŒMPSï¼Œå°†ä½¿ç”¨CPU")
            except:
                pass

            # è·å–æ¨èæ¨¡å‹å’ŒåŸå› 
            recommended_model, reason = self.get_recommended_model()
            self.log_message(f"ğŸ’¡ æ¨èä½¿ç”¨ {recommended_model} æ¨¡å‹ï¼ˆ{reason}ï¼‰")

    def select_videos(self):
        """é€‰æ‹©è§†é¢‘æ–‡ä»¶å’Œæ–‡ä»¶å¤¹"""
        dialog = QFileDialog(self)
        dialog.setFileMode(QFileDialog.ExistingFiles)  # å…è®¸é€‰æ‹©å¤šä¸ªæ–‡ä»¶
        dialog.setOption(QFileDialog.DontUseNativeDialog, True)  # ä½¿ç”¨Qtå¯¹è¯æ¡†ä»¥æ”¯æŒæ–‡ä»¶å¤¹é€‰æ‹©
        dialog.setNameFilter("è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mov *.wmv *.flv *.mkv *.webm *.m4v *.3gp);;æ‰€æœ‰æ–‡ä»¶ (*)")
        
        # æ·»åŠ æ–‡ä»¶å¤¹é€‰æ‹©æŒ‰é’®
        tree_view = dialog.findChild(QTreeView)
        if tree_view:
            tree_view.setSelectionMode(QAbstractItemView.ExtendedSelection)
        
        list_view = dialog.findChild(QListView)
        if list_view:
            list_view.setSelectionMode(QAbstractItemView.ExtendedSelection)

        # æ·»åŠ "é€‰æ‹©æ–‡ä»¶å¤¹"æŒ‰é’®
        folder_btn = QPushButton("é€‰æ‹©æ–‡ä»¶å¤¹", dialog)
        dialog.layout().addWidget(folder_btn)
        
        self.video_files = []  # æ¸…ç©ºä¹‹å‰çš„é€‰æ‹©
        
        def handle_folder_selection():
            folder = QFileDialog.getExistingDirectory(self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶å¤¹")
            if folder:
                # æ‰«ææ–‡ä»¶å¤¹ä¸­çš„è§†é¢‘æ–‡ä»¶
                video_extensions = ['.mp4', '.avi', '.mov', '.wmv', '.flv', '.mkv', '.webm', '.m4v', '.3gp']
                for root, dirs, files in os.walk(folder):
                    for file in files:
                        if any(file.lower().endswith(ext) for ext in video_extensions):
                            self.video_files.append(os.path.join(root, file))
                dialog.accept()  # å…³é—­å¯¹è¯æ¡†
        
        folder_btn.clicked.connect(handle_folder_selection)
        
        if dialog.exec_() == QFileDialog.Accepted:
            # è·å–é€‰æ‹©çš„æ–‡ä»¶
            selected_files = dialog.selectedFiles()
            for file in selected_files:
                if os.path.isfile(file):  # ç¡®ä¿æ˜¯æ–‡ä»¶è€Œä¸æ˜¯ç›®å½•
                    self.video_files.append(file)
            
            # æ›´æ–°ç•Œé¢æ˜¾ç¤º
            if self.video_files:
                if len(self.video_files) == 1:
                    self.video_label.setText(f"å·²é€‰æ‹©: {Path(self.video_files[0]).name}")
                else:
                    self.video_label.setText(f"å·²é€‰æ‹© {len(self.video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
                self.log_message(f"å…±é€‰æ‹©äº† {len(self.video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
                
                # æ˜¾ç¤ºæ‰€æœ‰é€‰æ‹©çš„æ–‡ä»¶è·¯å¾„
                self.log_message("é€‰æ‹©çš„æ–‡ä»¶:")
                for file in self.video_files:
                    self.log_message(f"  â€¢ {file}")
            else:
                self.video_label.setText("æœªé€‰æ‹©è§†é¢‘æ–‡ä»¶")

    def select_output_folder(self):
        """é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹"""
        folder = QFileDialog.getExistingDirectory(self, "é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹")

        if folder:
            self.output_folder = folder
            self.output_label.setText(f"è¾“å‡ºåˆ°: {Path(folder).name}")
            self.log_message(f"è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹: {folder}")

    def select_ffmpeg_path(self):
        """é€‰æ‹©ffmpegå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„"""
        file_filter = "ffmpeg (ffmpeg.exe);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "é€‰æ‹©ffmpegå¯æ‰§è¡Œæ–‡ä»¶",
            "",
            file_filter
        )

        if file_path:
            # éªŒè¯é€‰æ‹©çš„æ–‡ä»¶æ˜¯å¦æ˜¯ffmpeg
            try:
                result = subprocess.run([file_path, '-version'], 
                                     capture_output=True, 
                                     text=True, 
                                     timeout=5)
                if result.returncode == 0 and 'ffmpeg version' in result.stdout:
                    self.ffmpeg_path = file_path
                    self.ffmpeg_label.setText(f"å·²é€‰æ‹©: {Path(file_path).name}")
                    self.log_message(f"è®¾ç½®ffmpegè·¯å¾„: {file_path}")
                else:
                    QMessageBox.warning(self, "è­¦å‘Š", "æ‰€é€‰æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ffmpegå¯æ‰§è¡Œæ–‡ä»¶")
            except Exception as e:
                QMessageBox.warning(self, "è­¦å‘Š", f"éªŒè¯ffmpegå¤±è´¥: {str(e)}")

    def start_conversion(self):
        """å¼€å§‹è½¬æ¢"""
        if not self.video_files:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è§†é¢‘æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹")
            return

        if not self.output_folder:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹")
            return

        # æ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†
        dialog = ConfirmDialog(self.video_files, self)
        if dialog.exec_() != QDialog.Accepted:
            return

        # ç¦ç”¨å¼€å§‹æŒ‰é’®ï¼Œå¯ç”¨åœæ­¢æŒ‰é’®
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)

        # è·å–è®¾ç½®
        model_size = self.model_combo.currentText()
        use_gpu = self.gpu_checkbox.isChecked()

        # åˆ›å»ºå¹¶å¯åŠ¨å¤„ç†çº¿ç¨‹
        self.processor_thread = VideoProcessor(
            self.video_files,
            self.output_folder,
            model_size,
            use_gpu,
            self.ffmpeg_path
        )
        self.processor_thread.log_signal.connect(self.log_message)
        self.processor_thread.progress_signal.connect(self.update_progress)
        self.processor_thread.finished_signal.connect(self.conversion_finished)
        self.processor_thread.start()

    def stop_conversion(self):
        """åœæ­¢è½¬æ¢"""
        if self.processor_thread and self.processor_thread.isRunning():
            self.processor_thread.stop()
            self.log_message("æ­£åœ¨åœæ­¢è½¬æ¢...")

    def conversion_finished(self):
        """è½¬æ¢å®Œæˆ"""
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.progress_bar.setVisible(False)
        self.log_message("è½¬æ¢ä»»åŠ¡ç»“æŸ")

    def update_progress(self, value):
        """æ›´æ–°è¿›åº¦æ¡"""
        self.progress_bar.setValue(value)

    def log_message(self, message):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        timestamp = time.strftime("%H:%M:%S")
        self.log_text.append(f"[{timestamp}] {message}")
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.log_text.textCursor()
        cursor.movePosition(cursor.End)
        self.log_text.setTextCursor(cursor)

    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.clear()

    def show_gpu_diagnostic(self):
        """æ˜¾ç¤ºGPUè¯¦ç»†è¯Šæ–­"""
        self.log_message("\nğŸ” å¼€å§‹å®Œæ•´ç¯å¢ƒè¯Šæ–­...")

        # ç³»ç»Ÿä¿¡æ¯
        import platform
        self.log_message(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
        self.log_message(f"Pythonç‰ˆæœ¬: {platform.python_version()}")

        # ç¯å¢ƒå˜é‡æ£€æŸ¥
        self.log_message("\nğŸ“ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
        path_env = os.environ.get('PATH', '')
        ffmpeg_in_path = any('ffmpeg' in p.lower() for p in path_env.split(os.pathsep))
        self.log_message(f"PATHä¸­åŒ…å«ffmpeg: {'âœ…' if ffmpeg_in_path else 'âŒ'}")

        # æ‰‹åŠ¨æ£€æŸ¥ffmpeg
        self.log_message("\nğŸ¬ FFmpegè¯¦ç»†æ£€æŸ¥:")
        try:
            # ä½¿ç”¨whereå‘½ä»¤æŸ¥æ‰¾ffmpeg
            result = subprocess.run('where ffmpeg', shell=True, capture_output=True, text=True)
            if result.returncode == 0:
                ffmpeg_paths = result.stdout.strip().split('\n')
                for path in ffmpeg_paths:
                    if path.strip():
                        self.log_message(f"æ‰¾åˆ°ffmpeg: {path.strip()}")

                        # æµ‹è¯•è¿™ä¸ªffmpeg
                        try:
                            test_result = subprocess.run([path.strip(), '-version'],
                                                         capture_output=True, text=True, timeout=5)
                            if test_result.returncode == 0:
                                version_info = test_result.stdout.split('\n')[0]
                                self.log_message(f"âœ… {version_info}")
                            else:
                                self.log_message(f"âŒ è¯¥ffmpegæ— æ³•æ­£å¸¸è¿è¡Œ")
                        except Exception as e:
                            self.log_message(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            else:
                self.log_message("âŒ ç³»ç»Ÿæ‰¾ä¸åˆ°ffmpegå‘½ä»¤")
        except Exception as e:
            self.log_message(f"âŒ whereå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")

        # PyTorchä¿¡æ¯
        self.log_message(f"\nğŸ”¥ PyTorchä¿¡æ¯:")
        self.log_message(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        self.log_message(f"PyTorchç¼–è¯‘CUDAç‰ˆæœ¬: {torch.version.cuda}")

        # CUDAè¯¦ç»†æ£€æµ‹
        self.log_message(f"\nâš¡ CUDAæ£€æµ‹:")
        if torch.cuda.is_available():
            self.log_message("âœ… CUDA å®Œå…¨å¯ç”¨")
            self.log_message(f"CUDAè¿è¡Œæ—¶ç‰ˆæœ¬: {torch.version.cuda}")
            self.log_message(f"CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")

            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                self.log_message(f"GPU {i}: {props.name}")
                self.log_message(f"  æ˜¾å­˜: {props.total_memory / 1024 ** 3:.1f} GB")
                self.log_message(f"  è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")

                # æµ‹è¯•GPU
                try:
                    test_tensor = torch.randn(100, 100).cuda(i)
                    result = torch.matmul(test_tensor, test_tensor)
                    self.log_message(f"  âœ… GPU {i} æµ‹è¯•é€šè¿‡")
                except Exception as e:
                    self.log_message(f"  âŒ GPU {i} æµ‹è¯•å¤±è´¥: {e}")
        else:
            self.log_message("âŒ CUDA ä¸å¯ç”¨")

            # æ£€æŸ¥NVIDIAé©±åŠ¨
            self.log_message("\nğŸ” NVIDIAé©±åŠ¨æ£€æŸ¥:")
            try:
                result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, shell=True)
                if result.returncode == 0:
                    self.log_message("âœ… NVIDIAé©±åŠ¨å·²å®‰è£…")
                    # æå–GPUä¿¡æ¯
                    lines = result.stdout.split('\n')
                    for line in lines:
                        if 'NVIDIA-SMI' in line:
                            self.log_message(f"é©±åŠ¨ç‰ˆæœ¬: {line}")
                        elif 'GeForce' in line or 'RTX' in line or 'GTX' in line:
                            self.log_message(f"GPU: {line.strip()}")

                    self.log_message("ğŸ’¡ NVIDIAé©±åŠ¨æ­£å¸¸ï¼Œé—®é¢˜å¯èƒ½æ˜¯PyTorchç‰ˆæœ¬")
                    self.log_message("ğŸ’¡ è¯·é‡æ–°å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch:")
                    self.log_message("   pip uninstall torch torchvision torchaudio")
                    self.log_message(
                        "   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
                else:
                    self.log_message("âŒ nvidia-smi æ‰§è¡Œå¤±è´¥")
            except Exception as e:
                self.log_message(f"âŒ nvidia-smi å‘½ä»¤ä¸å­˜åœ¨: {e}")
                self.log_message("ğŸ’¡ è¯·å…ˆå®‰è£…NVIDIAæ˜¾å¡é©±åŠ¨")

        # Whisperæ£€æŸ¥
        self.log_message(f"\nğŸ™ï¸ Whisperæ£€æŸ¥:")
        try:
            import whisper
            self.log_message("âœ… Whisper å·²å®‰è£…")

            # æ˜¾ç¤ºæ¨èé…ç½®
            if torch.cuda.is_available():
                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
                if gpu_memory_gb >= 10:
                    self.log_message("ğŸ’¡ æ¨èä½¿ç”¨ large æ¨¡å‹è·å¾—æœ€ä½³æ•ˆæœ")
                elif gpu_memory_gb >= 5:
                    self.log_message("ğŸ’¡ æ¨èä½¿ç”¨ medium æ¨¡å‹å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡")
                else:
                    self.log_message("ğŸ’¡ æ¨èä½¿ç”¨ base æ¨¡å‹")
            else:
                self.log_message("ğŸ’¡ CPUæ¨¡å¼æ¨èä½¿ç”¨ tiny æˆ– base æ¨¡å‹")

        except ImportError:
            self.log_message("âŒ Whisper æœªå®‰è£…")
            self.log_message("ğŸ’¡ è¯·è¿è¡Œ: pip install openai-whisper")

        # è§£å†³æ–¹æ¡ˆæ±‡æ€»
        self.log_message(f"\nğŸ› ï¸ é—®é¢˜è§£å†³æ–¹æ¡ˆ:")

        if not ffmpeg_in_path:
            self.log_message("FFmpegé—®é¢˜:")
            self.log_message("1. ç¡®è®¤ffmpegå·²ä¸‹è½½å¹¶è§£å‹")
            self.log_message("2. å°†ffmpeg/binç›®å½•æ·»åŠ åˆ°ç³»ç»ŸPATH")
            self.log_message("3. é‡å¯å‘½ä»¤æç¤ºç¬¦å’Œç¨‹åº")
            self.log_message("4. æˆ–å°†ffmpeg.exeå¤åˆ¶åˆ°ç¨‹åºç›®å½•")

        if not torch.cuda.is_available():
            self.log_message("CUDAé—®é¢˜:")
            self.log_message("1. å®‰è£…æœ€æ–°NVIDIAæ˜¾å¡é©±åŠ¨")
            self.log_message("2. é‡æ–°å®‰è£…æ”¯æŒCUDAçš„PyTorch:")
            self.log_message("   pip uninstall torch torchvision torchaudio")
            self.log_message(
                "   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
            self.log_message("3. é‡å¯ç¨‹åºéªŒè¯")

        self.log_message("=" * 60)

    def update_model_recommendation(self, current_model):
        """æ›´æ–°æ¨¡å‹æ¨èæ ‡è®°"""
        recommended_model, reason = self.get_recommended_model()
        if current_model == recommended_model:
            self.model_recommended_label.setText(f"ï¼ˆæ¨èï¼š{reason}ï¼‰")
            self.model_recommended_label.setStyleSheet("color: green;")
        elif self.is_model_too_large(current_model):
            self.model_recommended_label.setText("ï¼ˆè­¦å‘Šï¼šå¯èƒ½å†…å­˜ä¸è¶³ï¼‰")
            self.model_recommended_label.setStyleSheet("color: red;")
        else:
            self.model_recommended_label.setText("")

    def is_model_too_large(self, model_name):
        """æ£€æŸ¥é€‰æ‹©çš„æ¨¡å‹æ˜¯å¦å¯èƒ½è¶…å‡ºç³»ç»Ÿèµ„æº"""
        if not torch.cuda.is_available():
            # CPUæ¨¡å¼ä¸‹ï¼Œlargeå’Œmediumæ¨¡å‹å¯èƒ½å¤ªå¤§
            return model_name in ["large", "medium"]
        else:
            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
            if gpu_memory_gb < 4 and model_name in ["large", "medium", "small"]:
                return True
            elif gpu_memory_gb < 6 and model_name in ["large", "medium"]:
                return True
            elif gpu_memory_gb < 8 and model_name == "large":
                return True
            return False

    def update_api_status(self, status_data):
        """æ›´æ–°APIæœåŠ¡çŠ¶æ€æ˜¾ç¤º"""
        status = status_data["status"]
        error = status_data["error"]
        task_count = status_data["task_count"]
        completed_tasks = status_data["completed_tasks"]

        # æ›´æ–°çŠ¶æ€æ ‡ç­¾
        status_text = f"æœåŠ¡çŠ¶æ€: {status}"
        if error:
            status_text += f" (é”™è¯¯: {error})"
        self.api_status_label.setText(status_text)

        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        self.api_start_btn.setEnabled(status != "running")
        self.api_stop_btn.setEnabled(status == "running")

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.api_stats.setText(f"ä»»åŠ¡ç»Ÿè®¡: æ€»æ•° {task_count} | å·²å®Œæˆ {completed_tasks}")

        # æ ¹æ®çŠ¶æ€è®¾ç½®æ ‡ç­¾é¢œè‰²
        if status == "running":
            self.api_status_label.setStyleSheet("color: green")
        elif status == "error":
            self.api_status_label.setStyleSheet("color: red")
        else:
            self.api_status_label.setStyleSheet("")

    def start_api_service(self):
        """å¯åŠ¨APIæœåŠ¡"""
        try:
            from api_service import APIServer, register_status_callback
            
            host = self.api_host_input.text()
            port = int(self.api_port_input.text())

            if self.api_server is None:
                self.api_server = APIServer(host=host, port=port)
                register_status_callback(self.update_api_status)

            if self.api_server.start():
                self.log_message(f"APIæœåŠ¡å¯åŠ¨æˆåŠŸ - {host}:{port}")
                self.log_message("APIæ¥å£:")
                self.log_message(f"  POST http://{host}:{port}/api/v1/transcribe")
                self.log_message(f"  GET  http://{host}:{port}/api/v1/tasks/{{task_id}}")
                self.log_message(f"  GET  http://{host}:{port}/api/v1/health")
            else:
                self.log_message("APIæœåŠ¡å·²åœ¨è¿è¡Œ")

        except Exception as e:
            self.log_message(f"APIæœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")
            QMessageBox.critical(self, "é”™è¯¯", f"APIæœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")

    def stop_api_service(self):
        """åœæ­¢APIæœåŠ¡"""
        if self.api_server and self.api_server.stop():
            self.log_message("APIæœåŠ¡å·²åœæ­¢")
        else:
            self.log_message("APIæœåŠ¡æœªåœ¨è¿è¡Œ")

    def closeEvent(self, event):
        """çª—å£å…³é—­æ—¶çš„å¤„ç†"""
        # åœæ­¢è§†é¢‘å¤„ç†
        if self.processor_thread and self.processor_thread.isRunning():
            self.stop_conversion()
        
        # åœæ­¢APIæœåŠ¡
        if self.api_server:
            self.api_server.stop()
        
        event.accept()


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='è§†é¢‘è½¬æ–‡å­—å·¥å…· - GUI/APIæ¨¡å¼')
    parser.add_argument('--mode', choices=['gui', 'api'], default='gui',
                      help='è¿è¡Œæ¨¡å¼: gui=å›¾å½¢ç•Œé¢æ¨¡å¼, api=APIæœåŠ¡æ¨¡å¼')
    parser.add_argument('--host', default='0.0.0.0',
                      help='APIæœåŠ¡ä¸»æœºåœ°å€ (ä»…åœ¨apiæ¨¡å¼ä¸‹æœ‰æ•ˆ)')
    parser.add_argument('--port', type=int, default=8000,
                      help='APIæœåŠ¡ç«¯å£ (ä»…åœ¨apiæ¨¡å¼ä¸‹æœ‰æ•ˆ)')
    args = parser.parse_args()

    if args.mode == 'api':
        print(f"å¯åŠ¨APIæœåŠ¡æ¨¡å¼ - ç›‘å¬åœ°å€: {args.host}:{args.port}")
        start_api_server(host=args.host, port=args.port)
    else:
        # GUIæ¨¡å¼
        app = QApplication.instance()
        if app is None:
            app = QApplication(sys.argv)
        
        # æ£€æŸ¥ä¾èµ–
        if not check_and_install_dependencies():
            QMessageBox.critical(None, "é”™è¯¯", "ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ§åˆ¶å°è¾“å‡º")
            return

        window = VideoAudioExtractorApp()
        window.show()
        sys.exit(app.exec_())


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        input("æŒ‰å›è½¦é”®é€€å‡º...")